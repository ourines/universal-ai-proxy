# Target configuration (existing)
TARGET_MODEL=moonshotai/kimi-k2-instruct
TARGET_PROVIDER=groq
TARGET_BASE_URL=https://api.groq.com/openai/v1
TARGET_MAX_TOKENS=16384

# UUID validation (existing)
REQUIRE_UUID=true
VALID_UUIDS=your-uuid-1,your-uuid-2,your-uuid-3

# Load balancing configuration (new)
LOAD_BALANCER_ENABLED=true
LOAD_BALANCER_STRATEGY=round-robin
LOAD_BALANCER_WINDOW_SIZE=5

# Load balancer API keys support multiple formats:
# Format 1: Simple keys (uses default TARGET_* settings)
# LOAD_BALANCER_API_KEYS=key1,key2,key3

# Format 2: Keys with weights
# LOAD_BALANCER_API_KEYS=key1:1,key2:2,key3:1

# Format 3: Full configuration per key (key:weight:provider:baseURL:model:maxTokens)
LOAD_BALANCER_API_KEYS=sk-groq-key:1:groq:https://api.groq.com/openai/v1:llama-3.3-70b-versatile:8192,sk-openai-key:2:openai:https://api.openai.com/v1:gpt-4o-mini:16384,sk-anthropic-key:1:anthropic:https://api.anthropic.com:claude-3-5-sonnet-20241022:8192

# Available strategies:
# - round-robin: Distributes requests evenly across all API keys/configs
# - time-window: Uses keys that haven't been used recently (windowSize in minutes)
# - weighted: Uses weights assigned to each key (higher weight = more requests)

# This allows you to:
# 1. Load balance between different AI providers (OpenAI, Anthropic, Groq, etc.)
# 2. Load balance between different models from the same provider
# 3. Use different API keys for different providers
# 4. Set different weights for different providers/models